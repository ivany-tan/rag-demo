{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924d4e1a-45ce-49f0-abe5-6eed8bf9f29b",
   "metadata": {},
   "source": [
    "# **Phase 0: Setting Up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f95795-6b78-4e5e-9563-5ddab2b86523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivantan/Desktop/rag-demo/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c75db8c4-0abd-4282-abbc-5692b832a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core libraries imported successfully!\n",
      "Timestamp: 2026-02-08 18:06:36\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv # Environment and configuration\n",
    "\n",
    "# LangChain core\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Document loaders\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    Docx2txtLoader,\n",
    ")\n",
    "\n",
    "from langchain_community.vectorstores import Chroma # Vector store\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI # LLM\n",
    "from rank_bm25 import BM25Okapi # BM25 for hybrid search\n",
    "import tiktoken # Token counting\n",
    "\n",
    "print(\"Core libraries imported successfully!\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2218334-54b8-4d85-a766-612863093829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 18:06:36 - IndustrialRAG - INFO - Logging system initialized\n",
      "2026-02-08 18:06:36 - IndustrialRAG - INFO - Starting Industrial RAG System Development\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# This helps track the RAG pipeline execution and identify bottlenecks\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger('IndustrialRAG')\n",
    "\n",
    "# Test logging\n",
    "logger.info(\"Logging system initialized\")\n",
    "logger.info(\"Starting Industrial RAG System Development\")\n",
    "print(\"Logging configured successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f138b84-2bd7-484f-8b57-daf57f11e90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 18:06:36 - IndustrialRAG - INFO - API Key loaded: AIzaSyAU...LT-U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API Key loaded successfully!\n",
      "Masked Key: AIzaSyAU...LT-U\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found in .env file!\")\n",
    "\n",
    "# Mask the key for security when logging\n",
    "masked_key = f\"{GOOGLE_API_KEY[:8]}...{GOOGLE_API_KEY[-4:]}\"\n",
    "logger.info(f\"API Key loaded: {masked_key}\")\n",
    "\n",
    "print(f\"Google API Key loaded successfully!\")\n",
    "print(f\"Masked Key: {masked_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401899a1-2ed6-4d37-bc40-7b19efd45b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses tiktoken (OpenAI's tokenizer) as a proxy for token estimation\n",
    "def count_tokens(text: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"\n",
    "    Count the number of tokens in a text string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        tokens = encoding.encode(text)\n",
    "        return len(tokens)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error counting tokens: {e}\")\n",
    "        # Fallback: rough estimation (1 token ≈ 4 characters)\n",
    "        return len(text) // 4\n",
    "\n",
    "def analyze_document(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"   \n",
    "    Strategy:\n",
    "    - Short docs (<2000 tokens): chunk_size=500, overlap=100\n",
    "    - Medium docs (2000-10000 tokens): chunk_size=1000, overlap=200\n",
    "    - Long docs (>10000 tokens): chunk_size=1500, overlap=300\n",
    "    Returns: Dictionary with token count and suggested chunk parameters\n",
    "    \"\"\"\n",
    "    token_count = count_tokens(text)\n",
    "    word_count = len(text.split())\n",
    "    char_count = len(text)\n",
    "    \n",
    "    # Determine optimal chunk size based on document length\n",
    "    if token_count < 2000:\n",
    "        chunk_size = 500\n",
    "        chunk_overlap = 100\n",
    "        strategy = \"small\"\n",
    "    elif token_count < 10000:\n",
    "        chunk_size = 1000\n",
    "        chunk_overlap = 200\n",
    "        strategy = \"medium\"\n",
    "    else:\n",
    "        chunk_size = 1500\n",
    "        chunk_overlap = 300\n",
    "        strategy = \"large\"\n",
    "    \n",
    "    analysis = {\n",
    "        \"token_count\": token_count,\n",
    "        \"word_count\": word_count,\n",
    "        \"char_count\": char_count,\n",
    "        \"suggested_chunk_size\": chunk_size,\n",
    "        \"suggested_overlap\": chunk_overlap,\n",
    "        \"strategy\": strategy\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"Document analysis: {token_count} tokens, strategy={strategy}\")\n",
    "    \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "335675f8-c970-41e3-95f9-e063f234e262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 18:06:36 - IndustrialRAG - INFO - Document analysis: 59 tokens, strategy=small\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token counter utility created!\n",
      "\n",
      "Test Document Analysis:\n",
      "    Tokens: 59\n",
      "    Words: 44\n",
      "    Characters: 326\n",
      "    Suggested chunk size: 500\n",
      "    Suggested overlap: 100\n",
      "    Strategy: small\n"
     ]
    }
   ],
   "source": [
    "# Test the token counter\n",
    "test_text = \"\"\"\n",
    "Artificial intelligence (AI) is transforming the world at an unprecedented pace.\n",
    "Machine learning, a subset of AI, enables computers to learn from data without\n",
    "explicit programming. Deep learning, using neural networks, has achieved remarkable\n",
    "results in computer vision, natural language processing, and speech recognition.\n",
    "\"\"\"\n",
    "\n",
    "analysis = analyze_document(test_text)\n",
    "\n",
    "print(\"Token counter utility created!\")\n",
    "print(f\"\\nTest Document Analysis:\")\n",
    "print(f\"    Tokens: {analysis['token_count']}\")\n",
    "print(f\"    Words: {analysis['word_count']}\")\n",
    "print(f\"    Characters: {analysis['char_count']}\")\n",
    "print(f\"    Suggested chunk size: {analysis['suggested_chunk_size']}\")\n",
    "print(f\"    Suggested overlap: {analysis['suggested_overlap']}\")\n",
    "print(f\"    Strategy: {analysis['strategy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e06ad-51bc-4c1f-8100-0239d4030624",
   "metadata": {},
   "source": [
    "# **Phase 2: Document Processing Pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c2245c-0763-4a35-85e6-dd9c5d585c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 18:06:36 - langchain_community.utils.user_agent - WARNING - USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredFileLoader, DirectoryLoader, WebBaseLoader\n",
    "\n",
    "def load(source: str) -> List[Document]:\n",
    "    \"\"\"Auto-detect and load file or directory using LangChain loaders.\"\"\"\n",
    "    \n",
    "    if source.startswith((\"http://\", \"https://\")):\n",
    "        loader = WebBaseLoader(source)\n",
    "        return loader.load()\n",
    "    \n",
    "    source_path = Path(source)\n",
    "    \n",
    "    if source_path.is_file():\n",
    "        loader = UnstructuredFileLoader(str(source_path))\n",
    "        return loader.load()\n",
    "        \n",
    "    elif source_path.is_dir():\n",
    "        loader = DirectoryLoader(\n",
    "            str(source_path),\n",
    "            glob=\"**/*\",\n",
    "            loader_cls=UnstructuredFileLoader,\n",
    "            use_multithreading=True\n",
    "        )\n",
    "        return loader.load()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid source: {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f782554-1f49-4aeb-aa33-ab785f98a5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 18:19:10 - unstructured - WARNING - libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    }
   ],
   "source": [
    "dir_doc = load(\"test_documents\")\n",
    "web_doc = load(\"https://karpathy.ai/\")\n",
    "all_doc = dir_doc + web_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a85801-4f96-4550-93ed-cb15b943570d",
   "metadata": {},
   "source": [
    "# **Phase 3: Chunking and Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce1862e3-1ee8-4bb3-a8bf-0405d4f18fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3: Chunking - Using LangChain's RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def create_chunks(documents: List[Document], chunk_size: int = 1000, chunk_overlap: int = 200) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Split documents into chunks using RecursiveCharacterTextSplitter.\n",
    "    Tries to split on paragraphs, then sentences, maintaining semantic coherence.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \";\", \" \", \"\"],\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    logger.info(f\"Split {len(documents)} documents into {len(chunks)} chunks\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f7c9300-6667-4357-9812-88efafb58b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 22:56:57 - IndustrialRAG - INFO - Split 4 documents into 113 chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 113 chunks from 4 documents\n",
      "\n",
      "\n",
      "First 100 chars in the first doc:\n",
      " # Retrieval\n",
      "\n",
      "Augmented Generation (RAG) Systems\n",
      "\n",
      "## Introduction Retrieval-Augmented Generation (RAG\n",
      "\n",
      "First 100 chars in the second doc:\n",
      " 5. **Query Processing**: When a user asks a question, it's converted into an embedding using the sam\n"
     ]
    }
   ],
   "source": [
    "# Chunk all documents\n",
    "all_chunks = create_chunks(all_doc)\n",
    "print(f\"Created {len(all_chunks)} chunks from {len(all_doc)} documents\\n\")\n",
    "print(\"\\nFirst 100 chars in the first doc:\\n\", all_chunks[0].page_content[:100])\n",
    "print(\"\\nFirst 100 chars in the second doc:\\n\", all_chunks[1].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1ada52e-f92f-4d54-83ea-825640fe84f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 23:11:59 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2026-02-08 23:11:59 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-08 23:11:59 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:11:59 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-08 23:11:59 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:12:00 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-08 23:12:00 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:12:00 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-08 23:12:00 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:12:00 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-08 23:12:00 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:12:00 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-08 23:12:00 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:12:01 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-08 23:12:01 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-08 23:12:01 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a6b7223af0478890fa6973cad36d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "2026-02-08 23:12:01 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-08 23:12:01 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:12:01 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-08 23:12:02 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:12:02 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-08 23:12:02 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:12:02 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-08 23:12:02 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:12:03 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
      "2026-02-08 23:12:03 - IndustrialRAG - INFO - Embeddings model initialized: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings model ready (384 dimensions)\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Embeddings - Using HuggingFace sentence-transformers\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'mps'},  # Use Apple Silicon GPU\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "logger.info(\"Embeddings model initialized: all-MiniLM-L6-v2\")\n",
    "print(\"Embeddings model ready (384 dimensions)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfb56071-2ae8-44ec-ad69-c661c8642140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 23:20:09 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2026-02-08 23:20:11 - IndustrialRAG - INFO - Vector store created with 113 chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store indexed: 113 chunks ready for retrieval\n"
     ]
    }
   ],
   "source": [
    "# Vector Store - Index all chunks in ChromaDB\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"rag_knowledge_base\"\n",
    ")\n",
    "\n",
    "logger.info(f\"Vector store created with {len(all_chunks)} chunks\")\n",
    "print(f\"Vector store indexed: {len(all_chunks)} chunks ready for retrieval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377d0e0-68cd-4d12-a686-6187c7d1afd8",
   "metadata": {},
   "source": [
    "# **Phase 4: Retrieval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a636f6d-8a7b-405e-8ffe-e182cf735feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 23:31:04 - IndustrialRAG - INFO - Retriever created with k=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever ready: will fetch top 10 candidates\n"
     ]
    }
   ],
   "source": [
    "# Phase 4: Retrieval - Create retriever from vector store\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 10}  # Retrieve top 10 candidates for re-ranking\n",
    ")\n",
    "\n",
    "logger.info(\"Retriever created with k=10\")\n",
    "print(\"Retriever ready: will fetch top 10 candidates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8f76c-6076-4318-97ad-8a37fa0bb2c6",
   "metadata": {},
   "source": [
    "## Retrieval Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4fc03e3-5b76-47ee-a4da-84f79aaadc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'What are the benefits of RAG systems?'\n",
      "Retrieved 10 documents\n",
      "\n",
      "**Result 1:**\n",
      "9\n",
      "\n",
      "Broader Impact\n",
      "\n",
      "This work offers several positive societal beneﬁts over previous work: the fact that it is more strongly grounded in real factual k...\n",
      "Source: test_documents/rag-for-knowledge-intensive-nlp-tasks.pdf\n",
      "\n",
      "**Result 2:**\n",
      ". Like T5 [51] or BART, RAG can be ﬁne-tuned on any seq2seq task, whereby both the generator and retriever are jointly learned....\n",
      "Source: test_documents/rag-for-knowledge-intensive-nlp-tasks.pdf\n",
      "\n",
      "**Result 3:**\n",
      "Acknowledgments\n",
      "\n",
      "The authors would like to thank the reviewers for their thoughtful and constructive feedback on this paper, as well as HuggingFace fo...\n",
      "Source: test_documents/rag-for-knowledge-intensive-nlp-tasks.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval with a query\n",
    "test_query = \"What are the benefits of RAG systems?\"\n",
    "results = retriever.invoke(test_query)\n",
    "\n",
    "print(f\"Query: '{test_query}'\")\n",
    "print(f\"Retrieved {len(results)} documents\\n\")\n",
    "\n",
    "for i, doc in enumerate(results[:3], 1):\n",
    "    print(f\"**Result {i}:**\")\n",
    "    print(f\"{doc.page_content[:150]}...\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a0944-721d-4552-81dc-0d40d5d960f9",
   "metadata": {},
   "source": [
    "## Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f6701-595f-439a-bf89-81314cd3c4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag-demo)",
   "language": "python",
   "name": "rag-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
